# rag_embed.py
import pandas as pd
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import pickle

# 1. CSV ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv("disease_region_filtered.csv")
print("ğŸ‘‰ CSV ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ")

# 2. í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
documents = df.apply(
    lambda row: f"{row['year']} {row['sidoNm']} {row['icdNm']} ë°œìƒ ê±´ìˆ˜ {row['resultVal']}ê±´",
    axis=1
).tolist()
print("ğŸ‘‰ í…ìŠ¤íŠ¸ ë³€í™˜ ì™„ë£Œ, ë¬¸ì„œ ê°œìˆ˜:", len(documents))

# 3. ì„ë² ë”© ìƒì„±
embed_model = SentenceTransformer("BAAI/bge-small-en-v1.5")
embeddings = embed_model.encode(
    documents,
    batch_size=16,
    normalize_embeddings=True,
    show_progress_bar=True
)
print("ğŸ‘‰ ì„ë² ë”© ì™„ë£Œ, shape:", embeddings.shape)

# 4. FAISS ì¸ë±ìŠ¤ ìƒì„±
dim = embeddings.shape[1]
index = faiss.IndexFlatL2(dim)
index.add(np.array(embeddings, dtype="float32"))
print("âœ… FAISSì— ë°ì´í„° ì €ì¥ ì™„ë£Œ!")

# 5. ì¸ë±ìŠ¤ì™€ ë¬¸ì„œ ì €ì¥ (pickle + faiss)
faiss.write_index(index, "faiss.index")
with open("documents.pkl", "wb") as f:
    pickle.dump(documents, f)

print("âœ… faiss.index + documents.pkl ì €ì¥ ì™„ë£Œ")

# 6. ì„ë² ë”© ê²€ì¦ (í…ŒìŠ¤íŠ¸ ê²€ìƒ‰)
query = "ì„œìš¸ ì—ë³¼ë¼ë°”ì´ëŸ¬ìŠ¤ë³‘ ë°œìƒ ê±´ìˆ˜"
query_emb = embed_model.encode([query], normalize_embeddings=True)

D, I = index.search(np.array(query_emb, dtype="float32"), k=5)
print("\nğŸ” ì„ë² ë”© ê²€ì¦ í…ŒìŠ¤íŠ¸")
print("í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬:", query)
for rank, idx in enumerate(I[0]):
    print(f"{rank+1}ìœ„ | {documents[idx]} (score={D[0][rank]:.4f})")
